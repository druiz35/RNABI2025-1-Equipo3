{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoC - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\\nfrom tensorflow.keras.metrics import AUC\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Machine Learning Preprocessing & Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, classification_report,\n",
    "                             roc_auc_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassAUROC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"feature_engineered_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268293 entries, 0 to 268292\n",
      "Data columns (total 64 columns):\n",
      " #   Column                               Non-Null Count   Dtype  \n",
      "---  ------                               --------------   -----  \n",
      " 0   loan_amnt                            268293 non-null  float64\n",
      " 1   funded_amnt                          268293 non-null  float64\n",
      " 2   funded_amnt_inv                      268293 non-null  float64\n",
      " 3   int_rate                             268293 non-null  float64\n",
      " 4   installment                          268293 non-null  float64\n",
      " 5   sub_grade                            268293 non-null  float64\n",
      " 6   emp_length                           268293 non-null  float64\n",
      " 7   annual_inc                           268293 non-null  float64\n",
      " 8   loan_status                          268293 non-null  float64\n",
      " 9   dti                                  268293 non-null  float64\n",
      " 10  delinq_2yrs                          268293 non-null  float64\n",
      " 11  inq_last_6mths                       268293 non-null  float64\n",
      " 12  open_acc                             268293 non-null  float64\n",
      " 13  pub_rec                              268293 non-null  float64\n",
      " 14  revol_bal                            268293 non-null  float64\n",
      " 15  revol_util                           268293 non-null  float64\n",
      " 16  total_acc                            268293 non-null  float64\n",
      " 17  out_prncp                            268293 non-null  float64\n",
      " 18  out_prncp_inv                        268293 non-null  float64\n",
      " 19  total_pymnt                          268293 non-null  float64\n",
      " 20  total_pymnt_inv                      268293 non-null  float64\n",
      " 21  total_rec_prncp                      268293 non-null  float64\n",
      " 22  total_rec_int                        268293 non-null  float64\n",
      " 23  total_rec_late_fee                   268293 non-null  float64\n",
      " 24  recoveries                           268293 non-null  float64\n",
      " 25  collection_recovery_fee              268293 non-null  float64\n",
      " 26  last_pymnt_amnt                      268293 non-null  float64\n",
      " 27  collections_12_mths_ex_med           268293 non-null  float64\n",
      " 28  acc_now_delinq                       268293 non-null  float64\n",
      " 29  tot_coll_amt                         268293 non-null  float64\n",
      " 30  tot_cur_bal                          268293 non-null  float64\n",
      " 31  total_rev_hi_lim                     268293 non-null  float64\n",
      " 32  term_ 36 months                      268293 non-null  bool   \n",
      " 33  term_ 60 months                      268293 non-null  bool   \n",
      " 34  home_ownership_MORTGAGE              268293 non-null  bool   \n",
      " 35  home_ownership_OWN                   268293 non-null  bool   \n",
      " 36  home_ownership_RENT                  268293 non-null  bool   \n",
      " 37  verification_status_Not Verified     268293 non-null  bool   \n",
      " 38  verification_status_Source Verified  268293 non-null  bool   \n",
      " 39  verification_status_Verified         268293 non-null  bool   \n",
      " 40  initial_list_status_f                268293 non-null  bool   \n",
      " 41  initial_list_status_w                268293 non-null  bool   \n",
      " 42  purpose_car                          268293 non-null  bool   \n",
      " 43  purpose_credit_card                  268293 non-null  bool   \n",
      " 44  purpose_debt_consolidation           268293 non-null  bool   \n",
      " 45  purpose_educational                  268293 non-null  bool   \n",
      " 46  purpose_home_improvement             268293 non-null  bool   \n",
      " 47  purpose_house                        268293 non-null  bool   \n",
      " 48  purpose_major_purchase               268293 non-null  bool   \n",
      " 49  purpose_medical                      268293 non-null  bool   \n",
      " 50  purpose_moving                       268293 non-null  bool   \n",
      " 51  purpose_other                        268293 non-null  bool   \n",
      " 52  purpose_renewable_energy             268293 non-null  bool   \n",
      " 53  purpose_small_business               268293 non-null  bool   \n",
      " 54  purpose_vacation                     268293 non-null  bool   \n",
      " 55  purpose_wedding                      268293 non-null  bool   \n",
      " 56  addr_state_hash_0                    268293 non-null  int64  \n",
      " 57  addr_state_hash_1                    268293 non-null  int64  \n",
      " 58  addr_state_hash_2                    268293 non-null  int64  \n",
      " 59  addr_state_hash_3                    268293 non-null  int64  \n",
      " 60  addr_state_hash_4                    268293 non-null  int64  \n",
      " 61  addr_state_hash_5                    268293 non-null  int64  \n",
      " 62  addr_state_hash_6                    268293 non-null  int64  \n",
      " 63  addr_state_hash_7                    268293 non-null  int64  \n",
      "dtypes: bool(24), float64(32), int64(8)\n",
      "memory usage: 88.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0.0    209526\n",
       "1.0     58767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"loan_status\"].astype(int)\n",
    "X = df.drop(columns=[\"loan_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split Train 70% Test 30%\n",
      "x_train shape: (187805, 63), y_train shape: (187805,)\n",
      "x_test shape: (80488, 63), y_test shape: (80488,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.3,\n",
    "    random_state = 35,\n",
    "    stratify = y,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"\\nData split Train 70% Test 30%\")\n",
    "print(f\"x_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training XGBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/druiz35/Documents/SEpsilon/SEpsilon-Proyectos/AI-ML-Data/CreditRiskScore/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [21:04:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training XGBoost ---\")\n",
    "xgb_classifier = XGBClassifier(\n",
    "    objective='multi:softmax', \n",
    "    num_class=2,       \n",
    "    n_estimators=500,          \n",
    "    learning_rate=0.1,         \n",
    "    max_depth=3,               \n",
    "    subsample=0.8,             \n",
    "    colsample_bytree=0.8,      \n",
    "    gamma=0,                   \n",
    "    reg_lambda=1,              \n",
    "    use_label_encoder=False,   \n",
    "    eval_metric='mlogloss',    # Evaluation metric for multi-class\n",
    "    random_state=35,\n",
    "    n_jobs=-1                  # Use all available cores\n",
    ")\n",
    "\n",
    "# Entrenamiento de XGBoost\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "print(\"XGBoost training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating XGBoost (Train Set) ---\n",
      "Train Accuracy: 0.9993\n",
      "Train F1 Score (Weighted): 0.9993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Paga       1.00      1.00      1.00    146668\n",
      "     No Paga       1.00      1.00      1.00     41137\n",
      "\n",
      "    accuracy                           1.00    187805\n",
      "   macro avg       1.00      1.00      1.00    187805\n",
      "weighted avg       1.00      1.00      1.00    187805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating XGBoost (Train Set) ---\")\n",
    "y_pred_train_xgb = xgb_classifier.predict(X_train)\n",
    "cm_train_xgb = confusion_matrix(y_train, y_pred_train_xgb)\n",
    "f1_train_xgb = f1_score(y_train, y_pred_train_xgb, average='weighted')\n",
    "acc_train_xgb = accuracy_score(y_train, y_pred_train_xgb)\n",
    "print(f\"Train Accuracy: {acc_train_xgb:.4f}\")\n",
    "print(f\"Train F1 Score (Weighted): {f1_train_xgb:.4f}\")\n",
    "# print(\"Train Classification Report:\") # Optional: uncomment for full report\n",
    "print(classification_report(y_train, y_pred_train_xgb, target_names=[\"Paga\", \"No Paga\"]))\n",
    "#plot_plotly_confusion_matrix(cm_train_xgb, class_labels, title='XGBoost Confusion Matrix (Train)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating XGBoost (Test Set) ---\n",
      "Test Accuracy: 0.9987\n",
      "Test F1 Score (Weighted): 0.9987\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Paga       1.00      1.00      1.00     62858\n",
      "     No Paga       1.00      0.99      1.00     17630\n",
      "\n",
      "    accuracy                           1.00     80488\n",
      "   macro avg       1.00      1.00      1.00     80488\n",
      "weighted avg       1.00      1.00      1.00     80488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating XGBoost (Test Set) ---\")\n",
    "y_pred_test_xgb = xgb_classifier.predict(X_test)\n",
    "cm_test_xgb = confusion_matrix(y_test, y_pred_test_xgb)\n",
    "f1_test_xgb = f1_score(y_test, y_pred_test_xgb, average='weighted')\n",
    "acc_test_xgb = accuracy_score(y_test, y_pred_test_xgb)\n",
    "print(f\"Test Accuracy: {acc_test_xgb:.4f}\")\n",
    "print(f\"Test F1 Score (Weighted): {f1_test_xgb:.4f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "# Use zero_division=0 to avoid warnings\n",
    "print(classification_report(y_test, y_pred_test_xgb, target_names=[\"Paga\", \"No Paga\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/druiz35/Documents/SEpsilon/SEpsilon-Proyectos/AI-ML-Data/CreditRiskScore/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [21:05:45] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPARA CARGAR EL MODELO:\\n* loaded_model = xgb.XGBClassifier()\\n* loaded_model.load_model(\"xgboost_model.model)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.save_model(\"xgboost_model.model\")\n",
    "\n",
    "\"\"\"\n",
    "PARA CARGAR EL MODELO:\n",
    "* loaded_model = xgb.XGBClassifier()\n",
    "* loaded_model.load_model(\"xgboost_model.model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset Translation for PyTorch\n",
    "boolean_columns = X_train.select_dtypes(include=\"bool\").columns\n",
    "\n",
    "X_train[boolean_columns] = X_train[boolean_columns].astype(int)\n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "X_test[boolean_columns] = X_test[boolean_columns].astype(int)\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader   = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "input_dim = df.shape[1] - 1\n",
    "n_classes = 2\n",
    "\n",
    "# Definición del modelo\n",
    "model = MLP(input_dim, n_classes)\n",
    "\n",
    "# Función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Metrics\n",
    "accuracy = MulticlassAccuracy(num_classes=len(set(y_train)))\n",
    "auc = MulticlassAUROC(num_classes=len(set(y_train)), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.0452 | Accuracy: 0.9769 | AUC: 0.9969\n",
      "Epoch [2/10]\n",
      "Train Loss: 0.0207 | Accuracy: 0.9903 | AUC: 0.9990\n",
      "Epoch [3/10]\n",
      "Train Loss: 0.0157 | Accuracy: 0.9926 | AUC: 0.9993\n",
      "Epoch [4/10]\n",
      "Train Loss: 0.0147 | Accuracy: 0.9931 | AUC: 0.9994\n",
      "Epoch [5/10]\n",
      "Train Loss: 0.0133 | Accuracy: 0.9940 | AUC: 0.9994\n",
      "Epoch [6/10]\n",
      "Train Loss: 0.0121 | Accuracy: 0.9945 | AUC: 0.9995\n",
      "Epoch [7/10]\n",
      "Train Loss: 0.0118 | Accuracy: 0.9946 | AUC: 0.9995\n",
      "Epoch [8/10]\n",
      "Train Loss: 0.0109 | Accuracy: 0.9950 | AUC: 0.9996\n",
      "Epoch [9/10]\n",
      "Train Loss: 0.0108 | Accuracy: 0.9953 | AUC: 0.9996\n",
      "Epoch [10/10]\n",
      "Train Loss: 0.0107 | Accuracy: 0.9954 | AUC: 0.9996\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    accuracy.reset()\n",
    "    auc.reset()\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch, y_batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        accuracy.update(outputs, y_batch)\n",
    "        auc.update(outputs, y_batch)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"Train Loss: {running_loss / len(train_loader):.4f} | Accuracy: {accuracy.compute():.4f} | AUC: {auc.compute():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9964 | Test AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy.reset()\n",
    "auc.reset()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch, y_batch\n",
    "        outputs = model(X_batch)\n",
    "        accuracy.update(outputs, y_batch)\n",
    "        auc.update(outputs, y_batch)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy.compute():.4f} | Test AUC: {auc.compute():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mlp_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
