{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept - Agente Creador de Narrativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from typing import Annotated, List\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "#from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "env_variables = dotenv_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir modelo LLM Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de memoria del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herramienta generadora de historias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@tool\n",
    "def generar_historia(\n",
    "    a\n",
    "): ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herramienta generadora de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupación de herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # StoryGenerationTool\n",
    "    # StoryQATool\n",
    "    # ImageGenerationTool\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de prompts 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_set_1 = {}\n",
    "prompt_set_1[\"main_prompt\"] = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"Eres un asistente de creación de narrativas que recibirá la siguiente información de parte del usuario para poder generar una historia:\"\n",
    "    \"* Género: La historia que puedes generar puede pertenecer a alguno de los siguientes géneros: Fantasía, Misterio, Romance, Terror, Ciencia Ficción, Comedia, Aventura.\"\n",
    "    \"* Tono: El tono de la historia en general. Puede ser uno de los siguientes: Humorístico, Oscuro, Caprichoso, Dramático, Satírico.\"\n",
    "    \"* Longitud de la historia: Puede ser corta (400 palabras), mediana (600 palabras) o larga (800 palabras).\"\n",
    "    \"* Personajes: El usuario puede agregar múltiples personajes a su historia, y por cada uno deberá especificar lo siguiente: Nombre, Rol, Rasgos de Personalidad, Relaciones.\"\n",
    "    \"* Escenario: El usuario deberá especificar lo siguiente con respecto al escenario: Período de Tiempo, Ubicación, Atmósfera.\"\n",
    "    \"* Elementos de trama: El usuario deberá especificar lo siguiente con respecto a cada uno de los elementos de la trama de la historia que desea: Tipo de Conflicto, Obstáculos, Estilo de Resolución.\"\n",
    "    \"La estructura narrativa de la historia a generar debe incluir inicio, nudo y desenlace.\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "prompt_set_1[\"story_prompt\"] = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_1[\"qa_prompt\"]  = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_1[\"image_prompt\"]  = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompts[\"set1\"] = prompt_set_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de prompts 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_set_2 = {}\n",
    "prompt_set_2[\"main_prompt\"] = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_2[\"story_prompt\"] = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_2[\"qa_prompt\"]  = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_2[\"image_prompt\"]  = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompts[\"set2\"] = prompt_set_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de prompts 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_set_3 = {}\n",
    "prompt_set_3[\"main_prompt\"] = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_3[\"story_prompt\"] = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_3[\"qa_prompt\"]  = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompt_set_3[\"image_prompt\"]  = ChatPromptTemplate([(\n",
    "    \"system\", \n",
    "    \"...\"\n",
    ")])\n",
    "prompts[\"set3\"] = prompt_set_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Agente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de conjunto de prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_prompt = prompts[\"set1\"]\n",
    "main_prompt = selected_prompt[\"main_prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de modelo, herramientas, memoria y prompt para agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(model, tools, main_prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    #memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversación 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\">\")\n",
    "    input_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"input\": user_input\n",
    "    }\n",
    "    response = agent_executor.invoke(\n",
    "        input_message\n",
    "    )\n",
    "    pprint(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversación 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversación 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversación 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversación 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
